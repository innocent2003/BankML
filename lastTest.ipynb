{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "Accuracy:  0.916\n",
      "Precision:  1.0\n",
      "recall:  0.0\n",
      "f1_score:  0.0\n",
      "Ty le du doan sai :  0.084\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "df = pd.read_csv('UniversalBank.csv')\n",
    "\n",
    "dt_train,dt_test = train_test_split(df,test_size=0.3,shuffle = False)\n",
    "\n",
    "# calculate error\n",
    "def error(y, y_pred):\n",
    "    sum = 0\n",
    "    for i in range(0, len(y)):\n",
    "        sum = sum + abs(y[i] - y_pred[i])\n",
    "    return sum/len(y)  # tra ve trung binh\n",
    "\n",
    "X_train = dt_train.iloc[:, :8]\n",
    "y_train = dt_train.iloc[:, 8]\n",
    "X_test = dt_test.iloc[:, :8]\n",
    "y_test = dt_test.iloc[:, 8]\n",
    "\n",
    "min=999999\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, validation_index in kf.split(dt_train):\n",
    "    X_train, X_validation = dt_train.iloc[train_index,:8], dt_train.iloc[validation_index, :8]\n",
    "    y_train, y_validation = dt_train.iloc[train_index, 8], dt_train.iloc[validation_index, 8]\n",
    "\n",
    "\n",
    "    svm = SVC().fit(X_train,y_train)\n",
    "    y_train_pred = svm.predict(X_train)\n",
    "    y_validation_pred = svm.predict(X_validation)\n",
    "    y_train = np.array(y_train)\n",
    "    y_validation = np.array(y_validation)\n",
    "\n",
    "    sum_error = error(y_train,y_train_pred) + error(y_validation, y_validation_pred)\n",
    "    \n",
    "    if(sum_error < min):\n",
    "        min = sum_error\n",
    "        regr=svm\n",
    "\n",
    "y_test_pred = regr.predict(dt_test.iloc[:,:8])\n",
    "y_test = np.array(dt_test.iloc[:,8])\n",
    "\n",
    "print(\"Perceptron:\")\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_test_pred))\n",
    "print(\"Precision: \",precision_score(y_test,y_test_pred,zero_division=1))# tỉ lệ số điểm true positive trong số những điểm được phân loại là positive\n",
    "print(\"recall: \",recall_score(y_test,y_test_pred,zero_division=1))# tỉ lệ số điểm true positive trong số những điểm thực sự là positive\n",
    "print(\"f1_score: \",f1_score(y_test,y_test_pred,zero_division=1))\n",
    "\n",
    "# đự đoán sai\n",
    "count = 0\n",
    "for i in range(0,len(y_test_pred)):\n",
    "    if(y_test[i] != y_test_pred[i]): count += 1\n",
    "\n",
    "print(\"Ty le du doan sai : \",count/len(y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "df = pd.read_csv('UniversalBank.csv')\n",
    "dt_train,dt_test = train_test_split(df,test_size=0.3,shuffle = False)\n",
    "\n",
    "# calculate error\n",
    "def error(y, y_pred):\n",
    "    sum = 0\n",
    "    for i in range(0, len(y)):\n",
    "        sum = sum + abs(y[i] - y_pred[i])\n",
    "    return sum/len(y)  # tra ve trung binh\n",
    "\n",
    "X_train = dt_train.iloc[:, :8]\n",
    "y_train = dt_train.iloc[:, 8]\n",
    "X_test = dt_test.iloc[:, :8]\n",
    "y_test = dt_test.iloc[:, 8]\n",
    "\n",
    "min=999999\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, validation_index in kf.split(dt_train):\n",
    "    X_train, X_validation = dt_train.iloc[train_index,:8], dt_train.iloc[validation_index, :8]\n",
    "    y_train, y_validation = dt_train.iloc[train_index, 8], dt_train.iloc[validation_index, 8]\n",
    "\n",
    "\n",
    "    per = Perceptron(alpha= 0.01).fit(X_train,y_train)\n",
    "    y_train_pred = per.predict(X_train)\n",
    "    y_validation_pred = per.predict(X_validation)\n",
    "    y_train = np.array(y_train)\n",
    "    y_validation = np.array(y_validation)\n",
    "\n",
    "    sum_error = error(y_train,y_train_pred) + error(y_validation, y_validation_pred)\n",
    "    \n",
    "    if(sum_error < min):\n",
    "        min = sum_error\n",
    "        regr=per\n",
    "\n",
    "y_test_pred = regr.predict(dt_test.iloc[:,:8])\n",
    "y_test = np.array(dt_test.iloc[:,8])\n",
    "\n",
    "print(\"Perceptron:\")\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_test_pred))\n",
    "print(\"Precision: \",precision_score(y_test,y_test_pred,zero_division=1))# tỉ lệ số điểm true positive trong số những điểm được phân loại là positive\n",
    "print(\"recall: \",recall_score(y_test,y_test_pred,zero_division=1))# tỉ lệ số điểm true positive trong số những điểm thực sự là positive\n",
    "print(\"f1_score: \",f1_score(y_test,y_test_pred,zero_division=1))\n",
    "\n",
    "# đự đoán sai\n",
    "count = 0\n",
    "for i in range(0,len(y_test_pred)):\n",
    "    if(y_test[i] != y_test_pred[i]): count += 1\n",
    "\n",
    "print(\"Ty le du doan sai : \",count/len(y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '[' (3507090344.py, line 61)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 61\u001b[1;36m\u001b[0m\n\u001b[1;33m    Gen_err.append(empirical_err + sqrt((2 * VC * log((e * x.shape[0]) / VC)) / x.shape[0]) + sqrt(log(1 / delta) / 2 * x.shape[0))\u001b[0m\n\u001b[1;37m                                                                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '['\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import Bounds, BFGS\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "from sklearn import datasets\n",
    "from math import log, e, sqrt, comb\n",
    "\n",
    "X, y = datasets.make_blobs(n_samples=100, centers=2, n_features=2, center_box=(0, 10), random_state=1)\n",
    "y[y == 0] = -1\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(\"\")\n",
    "\n",
    "epsilon = 1e-3\n",
    "\n",
    "def lagrange_dual(alpha, x, y, dim):\n",
    "    result_v = np.zeros(x.shape[0]).reshape(1, -1)\n",
    "    ind_sv = np.where(alpha > epsilon)[0]\n",
    "    for i in ind_sv:\n",
    "        result_v += alpha[i] * alpha * y[i] * y * ((np.dot(x[i].reshape(-1, 1).T, x.T)) ** dim)\n",
    "    result_v = 0.5 * result_v - alpha\n",
    "    return np.sum(result_v.reshape(-1, 1), axis=0)[0]\n",
    "\n",
    "def optimize_alpha(x, y, C, dim):\n",
    "    m, n = x.shape\n",
    "    np.random.seed(1)\n",
    "    alpha_0 = np.random.rand(m) * C\n",
    "    linear_constraint = LinearConstraint(y, [0], [0])\n",
    "    bounds_alpha = Bounds(np.zeros(m), np.full(m, C))\n",
    "    result = minimize(lagrange_dual, alpha_0, args=(x, y, dim), method='trust-constr', hess=BFGS(), constraints=[linear_constraint], bounds=bounds_alpha)\n",
    "    alpha = result.x\n",
    "    return alpha\n",
    "\n",
    "def calculate_w(alpha, y, x):\n",
    "    w = alpha.reshape(-1, 1) * y.reshape(-1, 1) * x\n",
    "    return np.sum(w, axis=0)\n",
    "\n",
    "def calculate_b(alpha, y, x, w, C, dim):\n",
    "    C_numeric = C - epsilon\n",
    "    ind_sv = np.where((alpha > epsilon) & (alpha < C_numeric))[0]\n",
    "    b = y[np.where((alpha > epsilon) & (alpha < C_numeric))[0]] - (np.dot(x[np.where((alpha > epsilon) & (alpha < C_numeric))[0]], w)) ** dim\n",
    "    b = b / len(ind_sv)\n",
    "    return np.sum(b)\n",
    "\n",
    "def classify_points(x, w, b, dim):\n",
    "    predicted_labels = np.sum((x * w) ** dim, axis=1) + b\n",
    "    predicted_labels = np.sign(predicted_labels)\n",
    "    predicted_labels[predicted_labels == 0] = -1\n",
    "    return predicted_labels\n",
    "\n",
    "def misclassification_rate(labels, predictions):\n",
    "    total = len(labels)\n",
    "    errors = sum(labels != predictions)\n",
    "    return errors / total\n",
    "\n",
    "def Gen_Error(empirical_err, x, VC, delta):\n",
    "    Gen_err = []\n",
    "    Gen_err.append(empirical_err + sqrt((8 / x.shape[0]) * log(((4 * (2 * x.shape[0]) ** VC) + 1) / delta)))\n",
    "    Gen_err.append(empirical_err + sqrt((2 * VC * log((e * x.shape[0]) / VC)) / x.shape[0]) + sqrt(log(1 / delta) / 2 * x.shape[0]))\n",
    "    return max(Gen_err)\n",
    "\n",
    "w, b, dim, _ = display_SVM_result(X_train, y_train, 100, 1, False)\n",
    "\n",
    "y_pred = classify_points(X_test, w, b, dim).astype(int)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian chạy: 0.0 giây\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Bắt đầu đo thời gian\n",
    "start_time = time.time()\n",
    "\n",
    "# Vòng lặp for\n",
    "for i in range(5000):\n",
    "    # Thực hiện các hành động của bạn ở đây\n",
    "    pass\n",
    "\n",
    "# Kết thúc đo thời gian và in kết quả\n",
    "end_time = time.time()\n",
    "print(\"Thời gian chạy: {} giây\".format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ tệp CSV\n",
    "df = pd.read_csv(\"UniversalBank.csv\")\n",
    "\n",
    "# Sử dụng .head(100) để lấy ra 100 hàng đầu tiên\n",
    "first_100_rows = df.head(100)\n",
    "\n",
    "# Hoặc bạn có thể sử dụng .iloc[:100]\n",
    "# first_100_rows = df.iloc[:100]\n",
    "\n",
    "# In ra 100 hàng đầu tiên\n",
    "first_100_rows.to_csv(\"100hang.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6064\\158733632.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0maccuracy_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Accuracy: {:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_test\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;31m# Call the function to display the SVM results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m \u001b[0mdisplay_SVM_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[0mexecution_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6064\\158733632.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y, C, dim, kernel)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay_SVM_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[0mVC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6064\\158733632.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(alpha, y, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6198\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6199\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6200\u001b[0m         ):\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6202\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import Bounds, BFGS\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "from sklearn import datasets\n",
    "from math import log, e, sqrt, comb\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "# Bắt đầu đo thời gian\n",
    "start_time = time.time()\n",
    "df = pd.read_csv(\"100hang.csv\")\n",
    "df['Personal Loan'].replace(0, -1, inplace=True)\n",
    "# df.head(30)\n",
    "X = df[['Age','Experience','Income','ZIP Code','Family','CCAvg','Education','Mortgage']].to_numpy()\n",
    "y = df['Personal Loan']\n",
    "epsilon = 1e-3\n",
    "\n",
    "\n",
    "def lagrange_dual(alpha, x, y, dim):\n",
    "    result_v = np.zeros(x.shape[0]).reshape(1, -1)\n",
    "    ind_sv = np.where(alpha > epsilon)[0]\n",
    "    for i in ind_sv:\n",
    "        # result_v += alpha[i] * alpha * y[i] * y * ((np.dot(x[i].reshape(-1, 1).T, x.T)) ** dim)\n",
    "        result_v += alpha[i] * alpha * y.to_numpy()[i] * y.to_numpy() * ((np.dot(x[i].reshape(-1, 1).T, x.T)) ** dim)\n",
    "\n",
    "    result_v = 0.5 * result_v - alpha\n",
    "    return np.sum(result_v.reshape(-1, 1), axis=0)[0]\n",
    "\n",
    "def optimize_alpha(x, y, C, dim):\n",
    "    m, n = x.shape\n",
    "    np.random.seed(1)\n",
    "    alpha_0 = np.random.rand(m) * C\n",
    "    linear_constraint = LinearConstraint(y, [0], [0])\n",
    "    bounds_alpha = Bounds(np.zeros(m), np.full(m, C))\n",
    "    result = minimize(lagrange_dual, alpha_0, args=(x, y, dim), method='trust-constr', hess=BFGS(), constraints=[linear_constraint], bounds=bounds_alpha)\n",
    "    alpha = result.x\n",
    "    return alpha\n",
    "\n",
    "def calculate_w(alpha, y, x):\n",
    "    w = alpha.reshape(-1, 1) * y.reshape(-1, 1) * x\n",
    "    return np.sum(w, axis=0)\n",
    "\n",
    "def calculate_b(alpha, y, x, w, C, dim):\n",
    "    C_numeric = C - epsilon\n",
    "    ind_sv = np.where((alpha > epsilon) & (alpha < C_numeric))[0]\n",
    "    b = y[np.where((alpha > epsilon) & (alpha < C_numeric))[0]] - (np.dot(x[np.where((alpha > epsilon) & (alpha < C_numeric))[0]], w)) ** dim\n",
    "    b = b / len(ind_sv)\n",
    "    return np.sum(b)\n",
    "\n",
    "def classify_points(x, w, b, dim):\n",
    "    predicted_labels = np.sum((x * w) ** dim, axis=1) + b\n",
    "    predicted_labels = np.sign(predicted_labels)\n",
    "    predicted_labels[predicted_labels == 0] = -1\n",
    "    return predicted_labels\n",
    "\n",
    "def misclassification_rate(labels, predictions):\n",
    "    total = len(labels)\n",
    "    errors = sum(labels != predictions)\n",
    "    return errors / total\n",
    "\n",
    "def Gen_Error(empirical_err, x, VC, delta):\n",
    "    Gen_err = []\n",
    "    Gen_err.append(empirical_err + sqrt((8 / x.shape[0]) * log(((4 * (2 * x.shape[0]) ** VC) + 1) / delta)))\n",
    "    Gen_err.append(empirical_err + sqrt((2 * VC * log((e * x.shape[0]) / VC)) / x.shape[0]) + sqrt(log(1 / delta) / 2 * x.shape[0]))\n",
    "    return max(Gen_err)\n",
    "\n",
    "\n",
    "    \n",
    "def accuracy_score(labels, predictions):\n",
    "    total = len(labels)\n",
    "    correct = sum(labels == predictions)\n",
    "    return correct / total\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# dt_train, dt_test = train_test_split(df,  test_size=0.25, random_state=0,shuffle=False)\n",
    "\n",
    "# X_train = dt_train.iloc[:, :8]\n",
    "# y_train = dt_train.iloc[:, 8]\n",
    "# X_test = dt_test.iloc[:, :8]\n",
    "# y_test = dt_test.iloc[:, 8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, shuffle=False)\n",
    "# def display_SVM_result(x, y, C, dim, kernel):\n",
    "#     alpha = optimize_alpha(x, y, C, dim)\n",
    "#     w = calculate_w(alpha, y, x)\n",
    "#     b = calculate_b(alpha, y, x, w, C, dim)\n",
    "    \n",
    "#     VC = w.shape[0] + dim\n",
    "#     delta = 0.5\n",
    "#     predictions = classify_points(x, w, b, dim)\n",
    "#     empirical_err = misclassification_rate(y, predictions)\n",
    "#     Gen_Error_Calc = Gen_Error(empirical_err, x, VC, delta)\n",
    "    \n",
    "#     # Calculate and print accuracy for both training and test datasets\n",
    "#     y_pred_train = classify_points(X_train, w, b, dim)\n",
    "#     accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "#     print(\"Training Accuracy: {:.2f}%\".format(accuracy_train * 100))\n",
    "    \n",
    "#     y_pred_test = classify_points(X_test, w, b, dim)\n",
    "#     accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "#     print(\"Test Accuracy: {:.2f}%\".format(accuracy_test * 100)) \n",
    "\n",
    "def display_SVM_result(x, y, C, dim, kernel):\n",
    "    alpha = optimize_alpha(x, y, C, dim)\n",
    "    w = calculate_w(alpha, y, x)\n",
    "    b = calculate_b(alpha, y, x, w, C, dim)\n",
    "\n",
    "    VC = w.shape[0] + dim\n",
    "    delta = 0.5\n",
    "    predictions = classify_points(x, w, b, dim)\n",
    "    empirical_err = misclassification_rate(y, predictions)\n",
    "    Gen_Error_Calc = Gen_Error(empirical_err, x, VC, delta)\n",
    "\n",
    "    # Calculate and print accuracy for both training and test datasets\n",
    "    y_pred_train = classify_points(X_train, w, b, dim)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Training Accuracy: {:.2f}%\".format(accuracy_train * 100))\n",
    "\n",
    "    y_pred_test = classify_points(X_test, w, b, dim)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    print(\"Test Accuracy: {:.2f}%\".format(accuracy_test * 100))\n",
    " \n",
    "# Call the function to display the SVM results\n",
    "display_SVM_result(X_train, y_train, 100, 1, False)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Thời gian chạy mã: {execution_time} giây\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2) (75,)\n",
      "(25, 2)\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'display_SVM_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\DataAnalysist\\BaiTapNhom4\\lastTest.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/DataAnalysist/BaiTapNhom4/lastTest.ipynb#W6sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     Gen_err\u001b[39m.\u001b[39mappend(empirical_err \u001b[39m+\u001b[39m sqrt((\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m VC \u001b[39m*\u001b[39m log((e \u001b[39m*\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m VC)) \u001b[39m/\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m sqrt(log(\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m delta) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/DataAnalysist/BaiTapNhom4/lastTest.ipynb#W6sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(Gen_err)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/DataAnalysist/BaiTapNhom4/lastTest.ipynb#W6sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m w, b, dim, _ \u001b[39m=\u001b[39m display_SVM_result(X_train, y_train, \u001b[39m100\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/DataAnalysist/BaiTapNhom4/lastTest.ipynb#W6sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m y_pred \u001b[39m=\u001b[39m classify_points(X_test, w, b, dim)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/DataAnalysist/BaiTapNhom4/lastTest.ipynb#W6sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mconcatenate((y_pred\u001b[39m.\u001b[39mreshape(\u001b[39mlen\u001b[39m(y_pred), \u001b[39m1\u001b[39m), y_test\u001b[39m.\u001b[39mreshape(\u001b[39mlen\u001b[39m(y_test), \u001b[39m1\u001b[39m)), \u001b[39m1\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'display_SVM_result' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import Bounds, BFGS\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "from sklearn import datasets\n",
    "from math import log, e, sqrt, comb\n",
    "\n",
    "X, y = datasets.make_blobs(n_samples=100, centers=2, n_features=2, center_box=(0, 10), random_state=1)\n",
    "y[y == 0] = -1\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(\"\")\n",
    "\n",
    "epsilon = 1e-3\n",
    "\n",
    "def lagrange_dual(alpha, x, y, dim):\n",
    "    result_v = np.zeros(x.shape[0]).reshape(1, -1)\n",
    "    ind_sv = np.where(alpha > epsilon)[0]\n",
    "    for i in ind_sv:\n",
    "        result_v += alpha[i] * alpha * y[i] * y * ((np.dot(x[i].reshape(-1, 1).T, x.T)) ** dim)\n",
    "    result_v = 0.5 * result_v - alpha\n",
    "    return np.sum(result_v.reshape(-1, 1), axis=0)[0]\n",
    "\n",
    "def optimize_alpha(x, y, C, dim):\n",
    "    m, n = x.shape\n",
    "    np.random.seed(1)\n",
    "    alpha_0 = np.random.rand(m) * C\n",
    "    linear_constraint = LinearConstraint(y, [0], [0])\n",
    "    bounds_alpha = Bounds(np.zeros(m), np.full(m, C))\n",
    "    result = minimize(lagrange_dual, alpha_0, args=(x, y, dim), method='trust-constr', hess=BFGS(), constraints=[linear_constraint], bounds=bounds_alpha)\n",
    "    alpha = result.x\n",
    "    return alpha\n",
    "\n",
    "def calculate_w(alpha, y, x):\n",
    "    w = alpha.reshape(-1, 1) * y.reshape(-1, 1) * x\n",
    "    return np.sum(w, axis=0)\n",
    "\n",
    "def calculate_b(alpha, y, x, w, C, dim):\n",
    "    C_numeric = C - epsilon\n",
    "    ind_sv = np.where((alpha > epsilon) & (alpha < C_numeric))[0]\n",
    "    b = y[np.where((alpha > epsilon) & (alpha < C_numeric))[0]] - (np.dot(x[np.where((alpha > epsilon) & (alpha < C_numeric))[0]], w)) ** dim\n",
    "    b = b / len(ind_sv)\n",
    "    return np.sum(b)\n",
    "\n",
    "def classify_points(x, w, b, dim):\n",
    "    predicted_labels = np.sum((x * w) ** dim, axis=1) + b\n",
    "    predicted_labels = np.sign(predicted_labels)\n",
    "    predicted_labels[predicted_labels == 0] = -1\n",
    "    return predicted_labels\n",
    "\n",
    "def misclassification_rate(labels, predictions):\n",
    "    total = len(labels)\n",
    "    errors = sum(labels != predictions)\n",
    "    return errors / total\n",
    "\n",
    "def Gen_Error(empirical_err, x, VC, delta):\n",
    "    Gen_err = []\n",
    "    Gen_err.append(empirical_err + sqrt((8 / x.shape[0]) * log(((4 * (2 * x.shape[0]) ** VC) + 1) / delta)))\n",
    "    Gen_err.append(empirical_err + sqrt((2 * VC * log((e * x.shape[0]) / VC)) / x.shape[0]) + sqrt(log(1 / delta) / 2 * x.shape[0]))\n",
    "    return max(Gen_err)\n",
    "\n",
    "w, b, dim, _ = display_SVM_result(X_train, y_train, 100, 1, False)\n",
    "\n",
    "y_pred = classify_points(X_test, w, b, dim).astype(int)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 60.00%\n",
      "Test Accuracy: 64.00%\n",
      "Thời gian chạy mã: 189.2664258480072 giây\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import Bounds, BFGS\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "from sklearn import datasets\n",
    "from math import log, e, sqrt, comb\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "# Bắt đầu đo thời gian\n",
    "start_time = time.time()\n",
    "df = pd.read_csv(\"100hang.csv\")\n",
    "df['Personal Loan'].replace(0, -1, inplace=True)\n",
    "# df.head(30)\n",
    "X = df[['Age','Experience','Income','ZIP Code','Family','CCAvg','Education','Mortgage']].to_numpy()\n",
    "y = df['Personal Loan'].values\n",
    "epsilon = 1e-3\n",
    "\n",
    "\n",
    "# def lagrange_dual(alpha, x, y, dim):\n",
    "#     result_v = np.zeros(x.shape[0]).reshape(1, -1)\n",
    "#     ind_sv = np.where(alpha > epsilon)[0]\n",
    "#     for i in ind_sv:\n",
    "#         # result_v += alpha[i] * alpha * y[i] * y * ((np.dot(x[i].reshape(-1, 1).T, x.T)) ** dim)\n",
    "#         result_v += alpha[i] * alpha * y.to_numpy()[i] * y.to_numpy() * ((np.dot(x[i].reshape(-1, 1).T, x.T)) ** dim)\n",
    "\n",
    "#     result_v = 0.5 * result_v - alpha\n",
    "#     return np.sum(result_v.reshape(-1, 1), axis=0)[0]\n",
    "\n",
    "def lagrange_dual(alpha, x, y, dim):\n",
    "    result_v = np.zeros(x.shape[0]).reshape(1, -1)\n",
    "    ind_sv = np.where(alpha > epsilon)[0]\n",
    "    for i in ind_sv:\n",
    "        result_v += alpha[i] * alpha * y[i] * y * ((np.dot(x[i].reshape(-1, 1).T, x.T)) ** dim)\n",
    "\n",
    "    result_v = 0.5 * result_v - alpha\n",
    "    return np.sum(result_v.reshape(-1, 1), axis=0)[0]\n",
    "\n",
    "def optimize_alpha(x, y, C, dim):\n",
    "    m, n = x.shape\n",
    "    np.random.seed(1)\n",
    "    alpha_0 = np.random.rand(m) * C\n",
    "    linear_constraint = LinearConstraint(y, [0], [0])\n",
    "    bounds_alpha = Bounds(np.zeros(m), np.full(m, C))\n",
    "    result = minimize(lagrange_dual, alpha_0, args=(x, y, dim), method='trust-constr', hess=BFGS(), constraints=[linear_constraint], bounds=bounds_alpha)\n",
    "    alpha = result.x\n",
    "    return alpha\n",
    "\n",
    "def calculate_w(alpha, y, x):\n",
    "    w = alpha.reshape(-1, 1) * y.reshape(-1, 1) * x\n",
    "    return np.sum(w, axis=0)\n",
    "\n",
    "def calculate_b(alpha, y, x, w, C, dim):\n",
    "    C_numeric = C - epsilon\n",
    "    ind_sv = np.where((alpha > epsilon) & (alpha < C_numeric))[0]\n",
    "    b = y[np.where((alpha > epsilon) & (alpha < C_numeric))[0]] - (np.dot(x[np.where((alpha > epsilon) & (alpha < C_numeric))[0]], w)) ** dim\n",
    "    b = b / len(ind_sv)\n",
    "    return np.sum(b)\n",
    "\n",
    "def classify_points(x, w, b, dim):\n",
    "    predicted_labels = np.sum((x * w) ** dim, axis=1) + b\n",
    "    predicted_labels = np.sign(predicted_labels)\n",
    "    predicted_labels[predicted_labels == 0] = -1\n",
    "    return predicted_labels\n",
    "\n",
    "def misclassification_rate(labels, predictions):\n",
    "    total = len(labels)\n",
    "    errors = sum(labels != predictions)\n",
    "    return errors / total\n",
    "\n",
    "def Gen_Error(empirical_err, x, VC, delta):\n",
    "    Gen_err = []\n",
    "    Gen_err.append(empirical_err + sqrt((8 / x.shape[0]) * log(((4 * (2 * x.shape[0]) ** VC) + 1) / delta)))\n",
    "    Gen_err.append(empirical_err + sqrt((2 * VC * log((e * x.shape[0]) / VC)) / x.shape[0]) + sqrt(log(1 / delta) / 2 * x.shape[0]))\n",
    "    return max(Gen_err)\n",
    "\n",
    "\n",
    "    \n",
    "def accuracy_score(labels, predictions):\n",
    "    total = len(labels)\n",
    "    correct = sum(labels == predictions)\n",
    "    return correct / total\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# dt_train, dt_test = train_test_split(df,  test_size=0.25, random_state=0,shuffle=False)\n",
    "\n",
    "# X_train = dt_train.iloc[:, :8]\n",
    "# y_train = dt_train.iloc[:, 8]\n",
    "# X_test = dt_test.iloc[:, :8]\n",
    "# y_test = dt_test.iloc[:, 8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, shuffle=False)\n",
    "# def display_SVM_result(x, y, C, dim, kernel):\n",
    "#     alpha = optimize_alpha(x, y, C, dim)\n",
    "#     w = calculate_w(alpha, y, x)\n",
    "#     b = calculate_b(alpha, y, x, w, C, dim)\n",
    "    \n",
    "#     VC = w.shape[0] + dim\n",
    "#     delta = 0.5\n",
    "#     predictions = classify_points(x, w, b, dim)\n",
    "#     empirical_err = misclassification_rate(y, predictions)\n",
    "#     Gen_Error_Calc = Gen_Error(empirical_err, x, VC, delta)\n",
    "    \n",
    "#     # Calculate and print accuracy for both training and test datasets\n",
    "#     y_pred_train = classify_points(X_train, w, b, dim)\n",
    "#     accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "#     print(\"Training Accuracy: {:.2f}%\".format(accuracy_train * 100))\n",
    "    \n",
    "#     y_pred_test = classify_points(X_test, w, b, dim)\n",
    "#     accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "#     print(\"Test Accuracy: {:.2f}%\".format(accuracy_test * 100)) \n",
    "\n",
    "def display_SVM_result(x, y, C, dim, kernel):\n",
    "    alpha = optimize_alpha(x, y, C, dim)\n",
    "    w = calculate_w(alpha, y, x)\n",
    "    b = calculate_b(alpha, y, x, w, C, dim)\n",
    "\n",
    "    VC = w.shape[0] + dim\n",
    "    delta = 0.5\n",
    "    predictions = classify_points(x, w, b, dim)\n",
    "    empirical_err = misclassification_rate(y, predictions)\n",
    "    Gen_Error_Calc = Gen_Error(empirical_err, x, VC, delta)\n",
    "\n",
    "    # Calculate and print accuracy for both training and test datasets\n",
    "    y_pred_train = classify_points(X_train, w, b, dim)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Training Accuracy: {:.2f}%\".format(accuracy_train * 100))\n",
    "\n",
    "    y_pred_test = classify_points(X_test, w, b, dim)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    print(\"Test Accuracy: {:.2f}%\".format(accuracy_test * 100))\n",
    " \n",
    "# Call the function to display the SVM results\n",
    "display_SVM_result(X_train, y_train, 100, 1, False)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Thời gian chạy mã: {execution_time} giây\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 67.56%\n",
      "Test Accuracy: 80.00%\n",
      "Thời gian chạy mã: 698.6638383865356 giây\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import Bounds, BFGS\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "from sklearn import datasets\n",
    "from math import log, e, sqrt, comb\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "# Bắt đầu đo thời gian\n",
    "start_time = time.time()\n",
    "df = pd.read_csv(\"UniversalBank.csv\",nrows=300)\n",
    "df['Personal Loan'].replace(0, -1, inplace=True)\n",
    "# df.head(30)\n",
    "X = df[['Age','Experience','Income','ZIP Code','Family','CCAvg','Education','Mortgage']].to_numpy()\n",
    "y = df['Personal Loan'].values\n",
    "epsilon = 1e-3\n",
    "\n",
    "\n",
    "# lagrange_dual(alpha, x, y, dim): Hàm này tính hàm lagrange đối với các giá trị alpha, dữ liệu x, nhãn y, và chiều dim. Nó sử dụng alpha để tính giá trị của hàm lagrange và trả về kết quả.\n",
    "\n",
    "# optimize_alpha(x, y, C, dim): Hàm này tối ưu hóa giá trị alpha dựa trên dữ liệu x, nhãn y, hằng số siêu tham số C, và chiều dim. Nó sử dụng phương pháp tối ưu hóa và ràng buộc để tìm giá trị alpha tối ưu và trả về alpha đã được tối ưu.\n",
    "\n",
    "# calculate_w(alpha, y, x): Hàm này tính vectơ trọng số w dựa trên các giá trị alpha, nhãn y, và dữ liệu x. Vectơ w này sẽ được sử dụng để xác định ranh giới quyết định của mô hình SVM.\n",
    "\n",
    "# calculate_b(alpha, y, x, w, C, dim): Hàm này tính giá trị b (tham số chặn) của mô hình SVM dựa trên các giá trị alpha, nhãn y, dữ liệu x, vectơ w, hằng số C, và chiều dim. b là một hệ số quan trọng trong việc xác định ranh giới quyết định của mô hình.\n",
    "\n",
    "# classify_points(x, w, b, dim): Hàm này sử dụng vectơ trọng số w, giá trị b, và chiều dim để dự đoán nhãn cho các điểm dữ liệu trong x. Nó tính toán các điểm dự đoán dựa trên công thức của mô hình SVM và trả về kết quả dưới dạng mảng các nhãn.\n",
    "\n",
    "# misclassification_rate(labels, predictions): Hàm này tính tỷ lệ lỗi dự đoán bằng cách so sánh nhãn thực tế (labels) với các dự đoán (predictions). Nó trả về tỷ lệ lỗi dự đoán.\n",
    "\n",
    "# Gen_Error(empirical_err, x, VC, delta): Hàm này tính tỷ lệ lỗi tổng quát (generalization error) dựa trên tỷ lệ lỗi thực nghiệm (empirical_err), số lượng các điểm dữ liệu (x), kích thước VC (VC), và giá trị delta (delta). Nó sử dụng các công thức được định nghĩa để tính toán tỷ lệ lỗi tổng quát dựa trên các thông số này.\n",
    "\n",
    "# accuracy_score(labels, predictions): Hàm này tính độ chính xác dựa trên nhãn thực tế (labels) và dự đoán (predictions). Nó đếm số lượng dự đoán đúng và tính tỷ lệ độ chính xác của mô hình.\n",
    "\n",
    "def lagrange_dual(alpha, x, y, dim):\n",
    "    result_v = np.zeros(x.shape[0]).reshape(1, -1)\n",
    "    ind_sv = np.where(alpha > epsilon)[0]\n",
    "    for i in ind_sv:\n",
    "        result_v += alpha[i] * alpha * y[i] * y * ((np.dot(x[i].reshape(-1, 1).T, x.T)) ** dim)\n",
    "\n",
    "    result_v = 0.5 * result_v - alpha\n",
    "    return np.sum(result_v.reshape(-1, 1), axis=0)[0]\n",
    "\n",
    "def optimize_alpha(x, y, C, dim):\n",
    "    m, n = x.shape\n",
    "    np.random.seed(1)\n",
    "    alpha_0 = np.random.rand(m) * C\n",
    "    linear_constraint = LinearConstraint(y, [0], [0])\n",
    "    bounds_alpha = Bounds(np.zeros(m), np.full(m, C))\n",
    "    result = minimize(lagrange_dual, alpha_0, args=(x, y, dim), method='trust-constr', hess=BFGS(), constraints=[linear_constraint], bounds=bounds_alpha)\n",
    "    alpha = result.x\n",
    "    return alpha\n",
    "\n",
    "def calculate_w(alpha, y, x):\n",
    "    w = alpha.reshape(-1, 1) * y.reshape(-1, 1) * x\n",
    "    return np.sum(w, axis=0)\n",
    "\n",
    "def calculate_b(alpha, y, x, w, C, dim):\n",
    "    C_numeric = C - epsilon\n",
    "    ind_sv = np.where((alpha > epsilon) & (alpha < C_numeric))[0]\n",
    "    b = y[np.where((alpha > epsilon) & (alpha < C_numeric))[0]] - (np.dot(x[np.where((alpha > epsilon) & (alpha < C_numeric))[0]], w)) ** dim\n",
    "    b = b / len(ind_sv)\n",
    "    return np.sum(b)\n",
    "\n",
    "def classify_points(x, w, b, dim):\n",
    "    predicted_labels = np.sum((x * w) ** dim, axis=1) + b\n",
    "    predicted_labels = np.sign(predicted_labels)\n",
    "    predicted_labels[predicted_labels == 0] = -1\n",
    "    return predicted_labels\n",
    "\n",
    "def misclassification_rate(labels, predictions):\n",
    "    total = len(labels)\n",
    "    errors = sum(labels != predictions)\n",
    "    return errors / total\n",
    "\n",
    "def Gen_Error(empirical_err, x, VC, delta):\n",
    "    Gen_err = []\n",
    "    Gen_err.append(empirical_err + sqrt((8 / x.shape[0]) * log(((4 * (2 * x.shape[0]) ** VC) + 1) / delta)))\n",
    "    Gen_err.append(empirical_err + sqrt((2 * VC * log((e * x.shape[0]) / VC)) / x.shape[0]) + sqrt(log(1 / delta) / 2 * x.shape[0]))\n",
    "    return max(Gen_err)\n",
    "\n",
    "\n",
    "    \n",
    "def accuracy_score(labels, predictions):\n",
    "    total = len(labels)\n",
    "    correct = sum(labels == predictions)\n",
    "    return correct / total\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# dt_train, dt_test = train_test_split(df,  test_size=0.25, random_state=0,shuffle=False)\n",
    "\n",
    "# X_train = dt_train.iloc[:, :8]\n",
    "# y_train = dt_train.iloc[:, 8]\n",
    "# X_test = dt_test.iloc[:, :8]\n",
    "# y_test = dt_test.iloc[:, 8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, shuffle=False)\n",
    "\n",
    "\n",
    "def display_SVM_result(x, y, C, dim, kernel):\n",
    "    alpha = optimize_alpha(x, y, C, dim)\n",
    "    w = calculate_w(alpha, y, x)\n",
    "    b = calculate_b(alpha, y, x, w, C, dim)\n",
    "\n",
    "    VC = w.shape[0] + dim\n",
    "    delta = 0.5\n",
    "    predictions = classify_points(x, w, b, dim)\n",
    "    empirical_err = misclassification_rate(y, predictions)\n",
    "    Gen_Error_Calc = Gen_Error(empirical_err, x, VC, delta)\n",
    "\n",
    "    # Calculate and print accuracy for both training and test datasets\n",
    "    y_pred_train = classify_points(X_train, w, b, dim)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Training Accuracy: {:.2f}%\".format(accuracy_train * 100))\n",
    "\n",
    "    y_pred_test = classify_points(X_test, w, b, dim)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    print(\"Test Accuracy: {:.2f}%\".format(accuracy_test * 100))\n",
    " \n",
    "# Call the function to display the SVM results\n",
    "display_SVM_result(X_train, y_train, 300, 1, False)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Thời gian chạy mã: {execution_time} giây\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.00%\n",
      "Test Accuracy: 64.00%\n",
      "Thời gian chạy mã: 1301.3719313144684 giây\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import Bounds, BFGS\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "from sklearn import datasets\n",
    "from math import log, e, sqrt, comb\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "# Bắt đầu đo thời gian\n",
    "start_time = time.time()\n",
    "df = pd.read_csv(\"UniversalBank.csv\",nrows=400)\n",
    "df['Personal Loan'].replace(0, -1, inplace=True)\n",
    "# df.head(30)\n",
    "X = df[['Age','Experience','Income','ZIP Code','Family','CCAvg','Education','Mortgage']].to_numpy()\n",
    "y = df['Personal Loan'].values\n",
    "epsilon = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lagrange_dual(alpha, x, y, dim):\n",
    "    result_v = np.zeros(x.shape[0]).reshape(1, -1)\n",
    "    ind_sv = np.where(alpha > epsilon)[0]\n",
    "    for i in ind_sv:\n",
    "        result_v += alpha[i] * alpha * y[i] * y * ((np.dot(x[i].reshape(-1, 1).T, x.T)) ** dim)\n",
    "\n",
    "    result_v = 0.5 * result_v - alpha\n",
    "    return np.sum(result_v.reshape(-1, 1), axis=0)[0]\n",
    "\n",
    "def optimize_alpha(x, y, C, dim):\n",
    "    m, n = x.shape\n",
    "    np.random.seed(1)\n",
    "    alpha_0 = np.random.rand(m) * C\n",
    "    linear_constraint = LinearConstraint(y, [0], [0])\n",
    "    bounds_alpha = Bounds(np.zeros(m), np.full(m, C))\n",
    "    result = minimize(lagrange_dual, alpha_0, args=(x, y, dim), method='trust-constr', hess=BFGS(), constraints=[linear_constraint], bounds=bounds_alpha)\n",
    "    alpha = result.x\n",
    "    return alpha\n",
    "\n",
    "def calculate_w(alpha, y, x):\n",
    "    w = alpha.reshape(-1, 1) * y.reshape(-1, 1) * x\n",
    "    return np.sum(w, axis=0)\n",
    "\n",
    "def calculate_b(alpha, y, x, w, C, dim):\n",
    "    C_numeric = C - epsilon\n",
    "    ind_sv = np.where((alpha > epsilon) & (alpha < C_numeric))[0]\n",
    "    b = y[np.where((alpha > epsilon) & (alpha < C_numeric))[0]] - (np.dot(x[np.where((alpha > epsilon) & (alpha < C_numeric))[0]], w)) ** dim\n",
    "    b = b / len(ind_sv)\n",
    "    return np.sum(b)\n",
    "\n",
    "def classify_points(x, w, b, dim):\n",
    "    predicted_labels = np.sum((x * w) ** dim, axis=1) + b\n",
    "    predicted_labels = np.sign(predicted_labels)\n",
    "    predicted_labels[predicted_labels == 0] = -1\n",
    "    return predicted_labels\n",
    "\n",
    "def misclassification_rate(labels, predictions):\n",
    "    total = len(labels)\n",
    "    errors = sum(labels != predictions)\n",
    "    return errors / total\n",
    "\n",
    "def Gen_Error(empirical_err, x, VC, delta):\n",
    "    Gen_err = []\n",
    "    Gen_err.append(empirical_err + sqrt((8 / x.shape[0]) * log(((4 * (2 * x.shape[0]) ** VC) + 1) / delta)))\n",
    "    Gen_err.append(empirical_err + sqrt((2 * VC * log((e * x.shape[0]) / VC)) / x.shape[0]) + sqrt(log(1 / delta) / 2 * x.shape[0]))\n",
    "    return max(Gen_err)\n",
    "\n",
    "\n",
    "    \n",
    "def accuracy_score(labels, predictions):\n",
    "    total = len(labels)\n",
    "    correct = sum(labels == predictions)\n",
    "    return correct / total\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# dt_train, dt_test = train_test_split(df,  test_size=0.25, random_state=0,shuffle=False)\n",
    "\n",
    "# X_train = dt_train.iloc[:, :8]\n",
    "# y_train = dt_train.iloc[:, 8]\n",
    "# X_test = dt_test.iloc[:, :8]\n",
    "# y_test = dt_test.iloc[:, 8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, shuffle=False)\n",
    "# def display_SVM_result(x, y, C, dim, kernel):\n",
    "#     alpha = optimize_alpha(x, y, C, dim)\n",
    "#     w = calculate_w(alpha, y, x)\n",
    "#     b = calculate_b(alpha, y, x, w, C, dim)\n",
    "    \n",
    "#     VC = w.shape[0] + dim\n",
    "#     delta = 0.5\n",
    "#     predictions = classify_points(x, w, b, dim)\n",
    "#     empirical_err = misclassification_rate(y, predictions)\n",
    "#     Gen_Error_Calc = Gen_Error(empirical_err, x, VC, delta)\n",
    "    \n",
    "#     # Calculate and print accuracy for both training and test datasets\n",
    "#     y_pred_train = classify_points(X_train, w, b, dim)\n",
    "#     accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "#     print(\"Training Accuracy: {:.2f}%\".format(accuracy_train * 100))\n",
    "    \n",
    "#     y_pred_test = classify_points(X_test, w, b, dim)\n",
    "#     accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "#     print(\"Test Accuracy: {:.2f}%\".format(accuracy_test * 100)) \n",
    "\n",
    "def display_SVM_result(x, y, C, dim, kernel):\n",
    "    alpha = optimize_alpha(x, y, C, dim)\n",
    "    w = calculate_w(alpha, y, x)\n",
    "    b = calculate_b(alpha, y, x, w, C, dim)\n",
    "\n",
    "    VC = w.shape[0] + dim\n",
    "    delta = 0.5\n",
    "    predictions = classify_points(x, w, b, dim)\n",
    "    empirical_err = misclassification_rate(y, predictions)\n",
    "    Gen_Error_Calc = Gen_Error(empirical_err, x, VC, delta)\n",
    "\n",
    "    # Calculate and print accuracy for both training and test datasets\n",
    "    y_pred_train = classify_points(X_train, w, b, dim)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Training Accuracy: {:.2f}%\".format(accuracy_train * 100))\n",
    "\n",
    "    y_pred_test = classify_points(X_test, w, b, dim)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    print(\"Test Accuracy: {:.2f}%\".format(accuracy_test * 100))\n",
    " \n",
    "# Call the function to display the SVM results\n",
    "display_SVM_result(X_train, y_train, 400, 1, False)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Thời gian chạy mã: {execution_time} giây\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Chúng ta sẽ sử dụng phương pháp Lagrange Multipliers để tối thiểu hóa hàm mục tiêu của chúng ta, mà trong trường hợp này là f(w,b) = ||w||^2/2.\"\n",
    "\n",
    "# Ý nghĩa: Code sử dụng phương pháp Lagrange Multipliers để tối thiểu hóa hàm mục tiêu f(w,b), mà trong trường hợp này là hàm mất mát của mô hình Support Vector Machine (SVM). Hàm mất mát này có dạng ||w||^2/2, nơi w là vectơ trọng số của mô hình SVM.\n",
    "# \"Phương pháp Lagrange Multipliers thêm hàm mục tiêu vào các ràng buộc của nó (có thể là ràng buộc bằng hoặc ràng buộc không bằng).\"\n",
    "\n",
    "# Ý nghĩa: Phương pháp Lagrange Multipliers thêm hàm mục tiêu (f(w,b)) vào các ràng buộc của nó để tạo ra một hàm Lagrangian. Trong trường hợp này, các ràng buộc là các ràng buộc của mô hình SVM.\n",
    "# \"Chúng ta sau đó nhân mỗi ràng buộc bằng một Lagrange Multiplier, trong trường hợp này là alpha.\"\n",
    "\n",
    "# Ý nghĩa: Mỗi ràng buộc của Lagrangian được nhân với một hệ số Lagrange Multiplier (alpha), là một biến để tối ưu hóa. Các alpha này sẽ được tối ưu hóa để đạt được giá trị tối thiểu cho hàm mục tiêu.\n",
    "# \"Chúng ta sau đó lấy đạo hàm của mỗi biến trong hàm Lagrange, và chúng là (w, b, alpha).\"\n",
    "\n",
    "# Ý nghĩa: Đạo hàm của Lagrangian đối với các biến (w, b, alpha) sẽ được tính để tìm điểm cực tiểu. Điều này dẫn đến một bài toán tối ưu hóa bậc hai, nơi chúng ta cố gắng tối ưu hóa các biến w, b, và alpha.\n",
    "# \"Chúng ta sau đó thay thế từng kết quả vào hàm Lagrange của chúng ta, và điều đó sẽ cho chúng ta Lagrangian gấp đôi, là một bài toán lập trình bậc hai (Quadratic programming problem).\"\n",
    "\n",
    "# Ý nghĩa: Bằng cách thay thế các kết quả của đạo hàm vào hàm Lagrange, chúng ta tạo ra một bài toán lập trình bậc hai (Quadratic programming problem) cần được giải quyết. Trong trường hợp này, chúng ta muốn tối ưu hóa Lagrangian để tìm ra giá trị tối thiểu cho hàm mục tiêu của mô hình SVM.\n",
    "# \"Chúng ta có thể sử dụng hàm minimize() trong scipy.optimize để giải quyết bài toán này và lấy được các giá trị alpha, nhưng chúng ta phải khởi tạo chúng trước bằng cách ngẫu nhiên.\"\n",
    "\n",
    "# Ý nghĩa: Để giải quyết bài toán tối ưu hóa, chúng ta sử dụng hàm minimize() trong thư viện SciPy để tìm các giá trị tối ưu cho alpha. Trước khi giải quyết, chúng ta phải khởi tạo giá trị ban đầu cho alpha bằng cách chọn ngẫu nhiên.\n",
    "# \"Sau đó chúng ta nhận được các tham số w và b.\"\n",
    "\n",
    "# Ý nghĩa: Sau khi giải quyết bài toán tối ưu hóa, chúng ta nhận được các giá trị tối ưu cho alpha, từ đó tính được các tham số w và b của mô hình SVM. Các tham số này xác định đường biên quyết định và ranh giới quyết định của mô hình SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lagrange_dual(alpha, x, y, dim): Hàm này tính hàm lagrange đối với các giá trị alpha, dữ liệu x, nhãn y, và chiều dim. Nó sử dụng alpha để tính giá trị của hàm lagrange và trả về kết quả.\n",
    "\n",
    "# optimize_alpha(x, y, C, dim): Hàm này tối ưu hóa giá trị alpha dựa trên dữ liệu x, nhãn y, hằng số siêu tham số C, và chiều dim. Nó sử dụng phương pháp tối ưu hóa và ràng buộc để tìm giá trị alpha tối ưu và trả về alpha đã được tối ưu.\n",
    "\n",
    "# calculate_w(alpha, y, x): Hàm này tính vectơ trọng số w dựa trên các giá trị alpha, nhãn y, và dữ liệu x. Vectơ w này sẽ được sử dụng để xác định ranh giới quyết định của mô hình SVM.\n",
    "\n",
    "# calculate_b(alpha, y, x, w, C, dim): Hàm này tính giá trị b (tham số chặn) của mô hình SVM dựa trên các giá trị alpha, nhãn y, dữ liệu x, vectơ w, hằng số C, và chiều dim. b là một hệ số quan trọng trong việc xác định ranh giới quyết định của mô hình.\n",
    "\n",
    "# classify_points(x, w, b, dim): Hàm này sử dụng vectơ trọng số w, giá trị b, và chiều dim để dự đoán nhãn cho các điểm dữ liệu trong x. Nó tính toán các điểm dự đoán dựa trên công thức của mô hình SVM và trả về kết quả dưới dạng mảng các nhãn.\n",
    "\n",
    "# misclassification_rate(labels, predictions): Hàm này tính tỷ lệ lỗi dự đoán bằng cách so sánh nhãn thực tế (labels) với các dự đoán (predictions). Nó trả về tỷ lệ lỗi dự đoán.\n",
    "\n",
    "# Gen_Error(empirical_err, x, VC, delta): Hàm này tính tỷ lệ lỗi tổng quát (generalization error) dựa trên tỷ lệ lỗi thực nghiệm (empirical_err), số lượng các điểm dữ liệu (x), kích thước VC (VC), và giá trị delta (delta). Nó sử dụng các công thức được định nghĩa để tính toán tỷ lệ lỗi tổng quát dựa trên các thông số này.\n",
    "\n",
    "# accuracy_score(labels, predictions): Hàm này tính độ chính xác dựa trên nhãn thực tế (labels) và dự đoán (predictions). Nó đếm số lượng dự đoán đúng và tính tỷ lệ độ chính xác của mô hình."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
